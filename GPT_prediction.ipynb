{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((323, 40, 100), (54, 40, 100))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data files\n",
    "x_train = np.load('data/X_train.npy')\n",
    "x_test = np.load('data/X_test.npy')\n",
    "\n",
    "# Checking the shapes of the datasets\n",
    "x_train_shape = x_train.shape\n",
    "x_test_shape = x_test.shape\n",
    "\n",
    "x_train_shape, x_test_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры после нормализации:\n",
      "Тренировочный набор: (258, 40, 100)\n",
      "Валидационный набор: (65, 40, 100)\n",
      "Тестовый набор: (54, 40, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Нормализация данных (StandardScaler делает нормализацию на основе среднего и стандартного отклонения)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Применяем нормализацию ко всем временным шагам и датчикам обучающего набора\n",
    "# Форма данных (наблюдения, датчики, время), поэтому нужно применить нормализацию вдоль датчиков (ось 1)\n",
    "x_train_reshaped = x_train.reshape(-1, x_train.shape[1])\n",
    "x_train_scaled = scaler.fit_transform(x_train_reshaped).reshape(x_train.shape)\n",
    "\n",
    "# Аналогично для тестовых данных\n",
    "x_test_reshaped = x_test.reshape(-1, x_test.shape[1])\n",
    "x_test_scaled = scaler.transform(x_test_reshaped).reshape(x_test.shape)\n",
    "\n",
    "# Разделение на тренировочный и валидационный набор (например, 80% для обучения, 20% для валидации)\n",
    "x_train_split, x_val_split = train_test_split(x_train_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Выводим размерности, чтобы проверить корректность обработки\n",
    "print(\"Размеры после нормализации:\")\n",
    "print(\"Тренировочный набор:\", x_train_split.shape)\n",
    "print(\"Валидационный набор:\", x_val_split.shape)\n",
    "print(\"Тестовый набор:\", x_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Study_projects_part_2\\Motorica_kaggle\\mototica_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.2950 - f1_score: 0.0017 - loss: 2.1114 - val_accuracy: 0.5385 - val_f1_score: 0.0635 - val_loss: 1.6538\n",
      "Epoch 2/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.5622 - f1_score: 0.0703 - loss: 1.6316 - val_accuracy: 0.5385 - val_f1_score: 0.0660 - val_loss: 1.6256\n",
      "Epoch 3/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.5444 - f1_score: 0.0583 - loss: 1.6526 - val_accuracy: 0.5385 - val_f1_score: 0.0669 - val_loss: 1.6487\n",
      "Epoch 4/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.5517 - f1_score: 0.0740 - loss: 1.6211 - val_accuracy: 0.5385 - val_f1_score: 0.0671 - val_loss: 1.5967\n",
      "Epoch 5/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.5666 - f1_score: 0.0724 - loss: 1.5185 - val_accuracy: 0.5385 - val_f1_score: 0.0628 - val_loss: 1.5246\n",
      "Epoch 6/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.5465 - f1_score: 0.0667 - loss: 1.5038 - val_accuracy: 0.5385 - val_f1_score: 0.0695 - val_loss: 1.4800\n",
      "Epoch 7/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.5594 - f1_score: 0.0772 - loss: 1.4173 - val_accuracy: 0.5391 - val_f1_score: 0.0685 - val_loss: 1.4408\n",
      "Epoch 8/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.5815 - f1_score: 0.0796 - loss: 1.3607 - val_accuracy: 0.5755 - val_f1_score: 0.0719 - val_loss: 1.3244\n",
      "Epoch 9/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.5993 - f1_score: 0.0901 - loss: 1.2554 - val_accuracy: 0.5922 - val_f1_score: 0.1113 - val_loss: 1.2186\n",
      "Epoch 10/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6355 - f1_score: 0.1333 - loss: 1.1617 - val_accuracy: 0.6183 - val_f1_score: 0.1272 - val_loss: 1.1482\n",
      "Epoch 11/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.6590 - f1_score: 0.1789 - loss: 1.0471 - val_accuracy: 0.6203 - val_f1_score: 0.1290 - val_loss: 1.1800\n",
      "Epoch 12/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.6587 - f1_score: 0.1828 - loss: 1.1318 - val_accuracy: 0.6448 - val_f1_score: 0.1544 - val_loss: 1.1472\n",
      "Epoch 13/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6464 - f1_score: 0.1776 - loss: 1.1330 - val_accuracy: 0.5942 - val_f1_score: 0.1454 - val_loss: 1.2153\n",
      "Epoch 14/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.6463 - f1_score: 0.2265 - loss: 1.1399 - val_accuracy: 0.6332 - val_f1_score: 0.1782 - val_loss: 1.1173\n",
      "Epoch 15/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6438 - f1_score: 0.2330 - loss: 1.1298 - val_accuracy: 0.6300 - val_f1_score: 0.1795 - val_loss: 1.1205\n",
      "Epoch 16/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.6778 - f1_score: 0.2824 - loss: 1.0596 - val_accuracy: 0.6363 - val_f1_score: 0.1726 - val_loss: 1.1115\n",
      "Epoch 17/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.6593 - f1_score: 0.2149 - loss: 1.0846 - val_accuracy: 0.6652 - val_f1_score: 0.2064 - val_loss: 0.9858\n",
      "Epoch 18/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.6863 - f1_score: 0.2965 - loss: 0.9736 - val_accuracy: 0.6917 - val_f1_score: 0.2061 - val_loss: 0.9536\n",
      "Epoch 19/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7094 - f1_score: 0.3023 - loss: 0.9629 - val_accuracy: 0.6895 - val_f1_score: 0.2077 - val_loss: 0.9386\n",
      "Epoch 20/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.6904 - f1_score: 0.2755 - loss: 0.9778 - val_accuracy: 0.6508 - val_f1_score: 0.2090 - val_loss: 0.9620\n",
      "Epoch 21/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7001 - f1_score: 0.3204 - loss: 0.9042 - val_accuracy: 0.7023 - val_f1_score: 0.2186 - val_loss: 1.0921\n",
      "Epoch 22/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.7044 - f1_score: 0.3202 - loss: 0.9568 - val_accuracy: 0.7115 - val_f1_score: 0.2256 - val_loss: 0.8725\n",
      "Epoch 23/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7128 - f1_score: 0.3506 - loss: 0.8800 - val_accuracy: 0.7015 - val_f1_score: 0.2500 - val_loss: 0.8182\n",
      "Epoch 24/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7227 - f1_score: 0.3529 - loss: 0.8757 - val_accuracy: 0.7266 - val_f1_score: 0.2584 - val_loss: 0.8055\n",
      "Epoch 25/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.7479 - f1_score: 0.3860 - loss: 0.7592 - val_accuracy: 0.7742 - val_f1_score: 0.3166 - val_loss: 0.6852\n",
      "Epoch 26/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.7180 - f1_score: 0.4470 - loss: 0.8006 - val_accuracy: 0.7220 - val_f1_score: 0.2907 - val_loss: 0.8703\n",
      "Epoch 27/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7430 - f1_score: 0.3877 - loss: 0.7940 - val_accuracy: 0.7275 - val_f1_score: 0.2768 - val_loss: 0.8409\n",
      "Epoch 28/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7560 - f1_score: 0.4159 - loss: 0.7791 - val_accuracy: 0.7186 - val_f1_score: 0.2738 - val_loss: 0.8067\n",
      "Epoch 29/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7461 - f1_score: 0.3867 - loss: 0.7341 - val_accuracy: 0.7446 - val_f1_score: 0.3107 - val_loss: 0.7187\n",
      "Epoch 30/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7477 - f1_score: 0.3896 - loss: 0.7656 - val_accuracy: 0.7394 - val_f1_score: 0.2931 - val_loss: 0.7206\n",
      "Epoch 31/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7508 - f1_score: 0.3996 - loss: 0.7018 - val_accuracy: 0.7688 - val_f1_score: 0.3191 - val_loss: 0.6532\n",
      "Epoch 32/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7619 - f1_score: 0.4305 - loss: 0.6891 - val_accuracy: 0.7349 - val_f1_score: 0.2860 - val_loss: 0.7451\n",
      "Epoch 33/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7548 - f1_score: 0.4023 - loss: 0.7506 - val_accuracy: 0.7475 - val_f1_score: 0.2937 - val_loss: 0.7755\n",
      "Epoch 34/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7516 - f1_score: 0.4087 - loss: 0.7479 - val_accuracy: 0.7815 - val_f1_score: 0.3178 - val_loss: 0.6457\n",
      "Epoch 35/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.7624 - f1_score: 0.4279 - loss: 0.6552 - val_accuracy: 0.7897 - val_f1_score: 0.3372 - val_loss: 0.6399\n",
      "Epoch 36/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7805 - f1_score: 0.4637 - loss: 0.6774 - val_accuracy: 0.7771 - val_f1_score: 0.3367 - val_loss: 0.6900\n",
      "Epoch 37/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7806 - f1_score: 0.4553 - loss: 0.6577 - val_accuracy: 0.8203 - val_f1_score: 0.3891 - val_loss: 0.5954\n",
      "Epoch 38/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8107 - f1_score: 0.5491 - loss: 0.5613 - val_accuracy: 0.7508 - val_f1_score: 0.3829 - val_loss: 0.6962\n",
      "Epoch 39/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7243 - f1_score: 0.4794 - loss: 0.8587 - val_accuracy: 0.6991 - val_f1_score: 0.2638 - val_loss: 0.8685\n",
      "Epoch 40/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7273 - f1_score: 0.3759 - loss: 0.7844 - val_accuracy: 0.7420 - val_f1_score: 0.3182 - val_loss: 0.7776\n",
      "Epoch 41/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.7648 - f1_score: 0.4665 - loss: 0.6874 - val_accuracy: 0.7889 - val_f1_score: 0.3617 - val_loss: 0.6703\n",
      "Epoch 42/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.7335 - f1_score: 0.4563 - loss: 0.8688 - val_accuracy: 0.7148 - val_f1_score: 0.3076 - val_loss: 0.8432\n",
      "Epoch 43/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7361 - f1_score: 0.4109 - loss: 0.8177 - val_accuracy: 0.7265 - val_f1_score: 0.2567 - val_loss: 0.7443\n",
      "Epoch 44/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7531 - f1_score: 0.4168 - loss: 0.6831 - val_accuracy: 0.8028 - val_f1_score: 0.3593 - val_loss: 0.6055\n",
      "Epoch 45/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.7712 - f1_score: 0.4355 - loss: 0.6590 - val_accuracy: 0.7903 - val_f1_score: 0.3451 - val_loss: 0.6049\n",
      "Epoch 46/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.7748 - f1_score: 0.4773 - loss: 0.6339 - val_accuracy: 0.7880 - val_f1_score: 0.3502 - val_loss: 0.6355\n",
      "Epoch 47/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7952 - f1_score: 0.4609 - loss: 0.6318 - val_accuracy: 0.8094 - val_f1_score: 0.4024 - val_loss: 0.5491\n",
      "Epoch 48/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8058 - f1_score: 0.5230 - loss: 0.5610 - val_accuracy: 0.7940 - val_f1_score: 0.3878 - val_loss: 0.5863\n",
      "Epoch 49/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8181 - f1_score: 0.5234 - loss: 0.5531 - val_accuracy: 0.7972 - val_f1_score: 0.3522 - val_loss: 0.5668\n",
      "Epoch 50/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8036 - f1_score: 0.4914 - loss: 0.5637 - val_accuracy: 0.7949 - val_f1_score: 0.3484 - val_loss: 0.5753\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step\n",
      "Предсказанные классы для тестового набора: [[0 0 4 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 5 5 5]\n",
      " [0 7 5 ... 0 0 0]\n",
      " [0 0 0 ... 4 4 4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Функция для вычисления F1-скора\n",
    "def f1_score(y_true, y_pred):\n",
    "    # Преобразуем вероятности предсказаний в бинарные метки\n",
    "    y_pred_binary = K.round(y_pred)\n",
    "\n",
    "    # Вычисляем True Positives, False Positives и False Negatives\n",
    "    tp = K.sum(K.cast(y_true * y_pred_binary, 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred_binary, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred_binary), 'float'), axis=0)\n",
    "\n",
    "    # Вычисляем Precision и Recall\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    # Вычисляем F1-скор\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    \n",
    "    # Усредняем по классам\n",
    "    f1 = K.mean(f1)\n",
    "    return f1\n",
    "\n",
    "# Транспонирование данных (наблюдения, временные шаги, датчики)\n",
    "x_train_scaled = np.transpose(x_train_scaled, (0, 2, 1))\n",
    "x_test_scaled = np.transpose(x_test_scaled, (0, 2, 1))\n",
    "\n",
    "# Создаем модель\n",
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])  # Форма входных данных (100 временных шагов, 40 датчиков)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Первый LSTM слой\n",
    "model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Второй LSTM слой\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Полносвязный слой\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Выходной слой\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# Компиляция модели с метрикой F1-score\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', f1_score])\n",
    "\n",
    "# Разделение данных на обучающие и валидационные выборки\n",
    "x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(x_train_scaled, y_train_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучение модели\n",
    "history = model.fit(x_train_split, y_train_split, \n",
    "                    validation_data=(x_val_split, y_val_split),\n",
    "                    epochs=50, batch_size=32)\n",
    "\n",
    "# Предсказания для тестового набора\n",
    "y_pred_test = model.predict(x_test_scaled)\n",
    "\n",
    "# Преобразование вероятностей в метки классов\n",
    "y_pred_classes = np.argmax(y_pred_test, axis=-1)\n",
    "\n",
    "# Выводим предсказанные классы для тестового набора\n",
    "print(\"Предсказанные классы для тестового набора:\", y_pred_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Файл с предсказаниями сохранен как data/submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Получение предсказаний\n",
    "y_pred_test = model.predict(x_test_scaled)\n",
    "\n",
    "# 2. Преобразование предсказаний в метки классов\n",
    "y_pred_classes = np.argmax(y_pred_test, axis=-1)  # Метки классов\n",
    "\n",
    "# 3. Форматирование предсказаний для соответствия файлу sample_submission.csv\n",
    "n_samples = y_pred_classes.shape[0]  # Количество тестовых образцов\n",
    "n_timesteps = y_pred_classes.shape[1]  # Количество временных шагов для каждого образца\n",
    "\n",
    "# Создаем списки для записи в submission\n",
    "sample_ids = []\n",
    "timestep_ids = []\n",
    "predicted_classes = []\n",
    "\n",
    "start_sample_index = 323  # Начинаем с 323, как указано\n",
    "\n",
    "for sample in range(n_samples):\n",
    "    for timestep in range(n_timesteps):\n",
    "        sample_ids.append(start_sample_index + sample)  # Индекс текущего образца начиная с 323\n",
    "        timestep_ids.append(timestep)  # Индекс текущего временного шага\n",
    "        predicted_classes.append(y_pred_classes[sample, timestep])  # Предсказанный класс для данного временного шага\n",
    "\n",
    "# 4. Создание DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    \"sample-timestep\": [f\"{sample}-{timestep}\" for sample, timestep in zip(sample_ids, timestep_ids)],\n",
    "    \"class\": predicted_classes\n",
    "})\n",
    "\n",
    "# 5. Сохранение предсказаний в файл submission.csv\n",
    "submission_file_path = 'data/submission.csv'\n",
    "submission_df.to_csv(submission_file_path, index=False)\n",
    "\n",
    "print(f\"Файл с предсказаниями сохранен как {submission_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mototica_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
